{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ8YW1GsTz+8xi82la7qLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GUNWOOOH/ADP_Practice/blob/main/%EA%B8%B0%EC%B6%9C%EB%B3%B5%EC%9B%90/%EA%B8%B0%EC%B6%9C%EB%B3%B5%EC%9B%90_ADP28_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADP 28회 기출복원\n",
        "\n",
        "1. 데이터 차원축소 목적 장단점 과적합 보완방안?(근데 실제로 이거 잘~말고 있나)\n",
        "\n",
        "tree base 모델이라서 과적합 방지용으로 imbalanced data SMOTE로 over sampling 하는 것이 답에 근사"
      ],
      "metadata": {
        "id": "wXmYls_hMLZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 언더샘플링\n",
        "\n",
        "1. 무작위추출 : 무작위로 정상 데이터를 일부만 선택\n",
        "\n",
        "2. 유의정보 : 유의한 데이터만을 남기는 방식(알고리즘 : EasyEnsemble, BalanceCascade)\n",
        "\n",
        "언더샘플링의 경우 데이터의 소실이 매우 크고, 때로는 중요한 정상데이터를 잃게 될 수 있다.\n",
        "\n",
        "\n",
        "# 오버샘플링\n",
        "\n",
        "1. 무작위추출 : 무작위로 소수 데이터를 복제\n",
        "\n",
        "2. 유의정보 : 사전에 기준을 정해서 소수 데이터를 복제\n",
        "\n",
        "정보가 손실되지 않는다는 장점이 있으나, 복제된 관측치를 원래 데이터 세트에 추가하기 만하면 여러 유형의 관측치를 다수 추가하여 오버 피팅 (overfitting)을 초래할 수 있다.\n",
        "\n",
        "이러한 경우 trainset의 성능은 높으나 testset의 성능은 나빠질 수 있다.\n",
        "\n",
        "3. 합성 데이터 생성 : 소수 데이터를 단순 복제하는 것이 아니라 새로운 복제본을 만들어 낸다.\n",
        "\n",
        "# 비용 민감 학습(Cost Sensitive Learning,CSL)\n",
        "\n",
        "오분류하는 행위를 비용으로 측정한다.\n",
        "\n",
        "Total Cost = C(FN)xFN + C(FP)xFP\n",
        "\n",
        "FN은 잘못 예측 된 긍정적인 관찰의 수\n",
        "\n",
        "FP는 잘못 예측 된 부정적 사례의 수\n",
        "\n",
        "C(FN)과 C(FP)는 False Negative 및 False Positive와 관련된 비용과 각각 일치한다. C(FN)> C(FP)\n",
        "\n",
        "잘못 분류된 비용을 설명하는 비용 매트릭스를 사용하여 불균형 학습 문제를 해결한다.\n",
        "\n",
        "최근의 이 방법론은 샘플링 기법으로의 대체로 대두되기도 한다."
      ],
      "metadata": {
        "id": "BwHwvQb6OPbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SMOTE알고리즘\n",
        "\n",
        "은 오버샘플링 기법 중 합성데이터를 생성하는 방식으로 가장 많이 사용되고 있는 모델이다.\n",
        "\n",
        "SMOTE(synthetic minority oversampling technique)란, 합성 소수 샘플링 기술로 다수 클래스를 샘플링하고 기존 소수 샘플을 보간하여 새로운 소수 인스턴스를 합성해낸다.\n",
        "\n",
        "일반적인 경우 성공적으로 작동하지만, 소수데이터들 사이를 보간하여 작동하기 때문에 모델링셋의 소수데이터들 사이의 특성만을 반영하고 새로운 사례의 데이터 예측엔 취약할 수 있다."
      ],
      "metadata": {
        "id": "VfjFejeMO2fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features = dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler.fit_transform(X_features)\n",
        "X_train = scaler.fit_transform(X_features)\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 모델설정\n",
        "sm = SMOTE( sampling_strategy='auto')\n",
        "\n",
        "# train데이터를 넣어 복제함\n",
        "X_resampled, y_resampled = sm.fit_resample(X_train,list(y_label))\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_resampled.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(X_resampled.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_resampled==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_resampled==0)))\n",
        "\n",
        "X_resampled.shape, y_resampled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ODaLsH65NXQH",
        "outputId": "27625134-5f7b-4762-a46b-843e87f4f930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After OverSampling, the shape of train_X: (714, 30)\n",
            "After OverSampling, the shape of train_y: (714, 30) \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a70004ee650c>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After OverSampling, the shape of train_y: {} \\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After OverSampling, counts of label '1': {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After OverSampling, counts of label '0': {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_resampled\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 2. LightGBM 랜덤포레스트 neuralnetwork\n"
      ],
      "metadata": {
        "id": "FHCbS18ONYkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lightgbm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
        "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
        "\n",
        "# 차트 스타일 설정\n",
        "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
        "plt.rc(\"figure\", figsize=(10,8))\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features = dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
        "\n",
        "# eval_set\n",
        "evals = [ (X_test, y_test) ]\n",
        "\n",
        "# 학습 (조기 중단 지정)\n",
        "lgbm_wrapper = LGBMClassifier(n_estimators=4000)\n",
        "lgbm_wrapper.fit(X_train, y_train,\n",
        "                 # 조기 중단 파라미터\n",
        "                 early_stopping_rounds = 100, eval_metric = \"logloss\", eval_set = evals, \n",
        "                 verbose=True)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba_po=None):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    auc = roc_auc_score(y_test, pred_proba_po)\n",
        "   \n",
        "    print(\"오차 행렬\")\n",
        "    print(confusion)\n",
        "    print(f\"정확도: {accuracy:.4f}, 정밀도: {precision:.4f}, 재현율: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
        "\n",
        "preds = lgbm_wrapper.predict(X_test)\n",
        "pred_proba = lgbm_wrapper.predict_proba(X_test)[:,1]\n",
        "\n",
        "# 평가\n",
        "get_clf_eval(y_test, preds, pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDgyzk_tNY51",
        "outputId": "d3e4db2e-8690-46aa-f8ff-022ca1d7e8fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.565079\n",
            "[2]\tvalid_0's binary_logloss: 0.507451\n",
            "[3]\tvalid_0's binary_logloss: 0.458489\n",
            "[4]\tvalid_0's binary_logloss: 0.417481\n",
            "[5]\tvalid_0's binary_logloss: 0.385507\n",
            "[6]\tvalid_0's binary_logloss: 0.355773\n",
            "[7]\tvalid_0's binary_logloss: 0.329587\n",
            "[8]\tvalid_0's binary_logloss: 0.308478\n",
            "[9]\tvalid_0's binary_logloss: 0.285395\n",
            "[10]\tvalid_0's binary_logloss: 0.267055\n",
            "[11]\tvalid_0's binary_logloss: 0.252013\n",
            "[12]\tvalid_0's binary_logloss: 0.237018\n",
            "[13]\tvalid_0's binary_logloss: 0.224756\n",
            "[14]\tvalid_0's binary_logloss: 0.213383\n",
            "[15]\tvalid_0's binary_logloss: 0.203058\n",
            "[16]\tvalid_0's binary_logloss: 0.194015\n",
            "[17]\tvalid_0's binary_logloss: 0.186412\n",
            "[18]\tvalid_0's binary_logloss: 0.179108\n",
            "[19]\tvalid_0's binary_logloss: 0.174004\n",
            "[20]\tvalid_0's binary_logloss: 0.167155\n",
            "[21]\tvalid_0's binary_logloss: 0.162494\n",
            "[22]\tvalid_0's binary_logloss: 0.156886\n",
            "[23]\tvalid_0's binary_logloss: 0.152855\n",
            "[24]\tvalid_0's binary_logloss: 0.151113\n",
            "[25]\tvalid_0's binary_logloss: 0.148395\n",
            "[26]\tvalid_0's binary_logloss: 0.145869\n",
            "[27]\tvalid_0's binary_logloss: 0.143036\n",
            "[28]\tvalid_0's binary_logloss: 0.14033\n",
            "[29]\tvalid_0's binary_logloss: 0.139609\n",
            "[30]\tvalid_0's binary_logloss: 0.136109\n",
            "[31]\tvalid_0's binary_logloss: 0.134867\n",
            "[32]\tvalid_0's binary_logloss: 0.134729\n",
            "[33]\tvalid_0's binary_logloss: 0.1311\n",
            "[34]\tvalid_0's binary_logloss: 0.131143\n",
            "[35]\tvalid_0's binary_logloss: 0.129435\n",
            "[36]\tvalid_0's binary_logloss: 0.128474\n",
            "[37]\tvalid_0's binary_logloss: 0.126683\n",
            "[38]\tvalid_0's binary_logloss: 0.126112\n",
            "[39]\tvalid_0's binary_logloss: 0.122831\n",
            "[40]\tvalid_0's binary_logloss: 0.123162\n",
            "[41]\tvalid_0's binary_logloss: 0.125592\n",
            "[42]\tvalid_0's binary_logloss: 0.128293\n",
            "[43]\tvalid_0's binary_logloss: 0.128123\n",
            "[44]\tvalid_0's binary_logloss: 0.12789\n",
            "[45]\tvalid_0's binary_logloss: 0.122818\n",
            "[46]\tvalid_0's binary_logloss: 0.12496\n",
            "[47]\tvalid_0's binary_logloss: 0.125578\n",
            "[48]\tvalid_0's binary_logloss: 0.127381\n",
            "[49]\tvalid_0's binary_logloss: 0.128349\n",
            "[50]\tvalid_0's binary_logloss: 0.127004\n",
            "[51]\tvalid_0's binary_logloss: 0.130288\n",
            "[52]\tvalid_0's binary_logloss: 0.131362\n",
            "[53]\tvalid_0's binary_logloss: 0.133363\n",
            "[54]\tvalid_0's binary_logloss: 0.1332\n",
            "[55]\tvalid_0's binary_logloss: 0.134543\n",
            "[56]\tvalid_0's binary_logloss: 0.130803\n",
            "[57]\tvalid_0's binary_logloss: 0.130306\n",
            "[58]\tvalid_0's binary_logloss: 0.132514\n",
            "[59]\tvalid_0's binary_logloss: 0.133278\n",
            "[60]\tvalid_0's binary_logloss: 0.134804\n",
            "[61]\tvalid_0's binary_logloss: 0.136888\n",
            "[62]\tvalid_0's binary_logloss: 0.138745\n",
            "[63]\tvalid_0's binary_logloss: 0.140497\n",
            "[64]\tvalid_0's binary_logloss: 0.141368\n",
            "[65]\tvalid_0's binary_logloss: 0.140764\n",
            "[66]\tvalid_0's binary_logloss: 0.14348\n",
            "[67]\tvalid_0's binary_logloss: 0.143418\n",
            "[68]\tvalid_0's binary_logloss: 0.143682\n",
            "[69]\tvalid_0's binary_logloss: 0.145076\n",
            "[70]\tvalid_0's binary_logloss: 0.14686\n",
            "[71]\tvalid_0's binary_logloss: 0.148051\n",
            "[72]\tvalid_0's binary_logloss: 0.147664\n",
            "[73]\tvalid_0's binary_logloss: 0.149478\n",
            "[74]\tvalid_0's binary_logloss: 0.14708\n",
            "[75]\tvalid_0's binary_logloss: 0.14545\n",
            "[76]\tvalid_0's binary_logloss: 0.148767\n",
            "[77]\tvalid_0's binary_logloss: 0.149959\n",
            "[78]\tvalid_0's binary_logloss: 0.146083\n",
            "[79]\tvalid_0's binary_logloss: 0.14638\n",
            "[80]\tvalid_0's binary_logloss: 0.148461\n",
            "[81]\tvalid_0's binary_logloss: 0.15091\n",
            "[82]\tvalid_0's binary_logloss: 0.153011\n",
            "[83]\tvalid_0's binary_logloss: 0.154807\n",
            "[84]\tvalid_0's binary_logloss: 0.156501\n",
            "[85]\tvalid_0's binary_logloss: 0.158586\n",
            "[86]\tvalid_0's binary_logloss: 0.159819\n",
            "[87]\tvalid_0's binary_logloss: 0.161745\n",
            "[88]\tvalid_0's binary_logloss: 0.162829\n",
            "[89]\tvalid_0's binary_logloss: 0.159142\n",
            "[90]\tvalid_0's binary_logloss: 0.156765\n",
            "[91]\tvalid_0's binary_logloss: 0.158625\n",
            "[92]\tvalid_0's binary_logloss: 0.156832\n",
            "[93]\tvalid_0's binary_logloss: 0.154616\n",
            "[94]\tvalid_0's binary_logloss: 0.154263\n",
            "[95]\tvalid_0's binary_logloss: 0.157156\n",
            "[96]\tvalid_0's binary_logloss: 0.158617\n",
            "[97]\tvalid_0's binary_logloss: 0.157495\n",
            "[98]\tvalid_0's binary_logloss: 0.159413\n",
            "[99]\tvalid_0's binary_logloss: 0.15847\n",
            "[100]\tvalid_0's binary_logloss: 0.160746\n",
            "[101]\tvalid_0's binary_logloss: 0.16217\n",
            "[102]\tvalid_0's binary_logloss: 0.165293\n",
            "[103]\tvalid_0's binary_logloss: 0.164749\n",
            "[104]\tvalid_0's binary_logloss: 0.167097\n",
            "[105]\tvalid_0's binary_logloss: 0.167697\n",
            "[106]\tvalid_0's binary_logloss: 0.169462\n",
            "[107]\tvalid_0's binary_logloss: 0.169947\n",
            "[108]\tvalid_0's binary_logloss: 0.171\n",
            "[109]\tvalid_0's binary_logloss: 0.16907\n",
            "[110]\tvalid_0's binary_logloss: 0.169521\n",
            "[111]\tvalid_0's binary_logloss: 0.167719\n",
            "[112]\tvalid_0's binary_logloss: 0.166648\n",
            "[113]\tvalid_0's binary_logloss: 0.169053\n",
            "[114]\tvalid_0's binary_logloss: 0.169613\n",
            "[115]\tvalid_0's binary_logloss: 0.170059\n",
            "[116]\tvalid_0's binary_logloss: 0.1723\n",
            "[117]\tvalid_0's binary_logloss: 0.174733\n",
            "[118]\tvalid_0's binary_logloss: 0.173526\n",
            "[119]\tvalid_0's binary_logloss: 0.1751\n",
            "[120]\tvalid_0's binary_logloss: 0.178254\n",
            "[121]\tvalid_0's binary_logloss: 0.182968\n",
            "[122]\tvalid_0's binary_logloss: 0.179017\n",
            "[123]\tvalid_0's binary_logloss: 0.178326\n",
            "[124]\tvalid_0's binary_logloss: 0.177149\n",
            "[125]\tvalid_0's binary_logloss: 0.179171\n",
            "[126]\tvalid_0's binary_logloss: 0.180948\n",
            "[127]\tvalid_0's binary_logloss: 0.183861\n",
            "[128]\tvalid_0's binary_logloss: 0.187579\n",
            "[129]\tvalid_0's binary_logloss: 0.188122\n",
            "[130]\tvalid_0's binary_logloss: 0.1857\n",
            "[131]\tvalid_0's binary_logloss: 0.187442\n",
            "[132]\tvalid_0's binary_logloss: 0.188578\n",
            "[133]\tvalid_0's binary_logloss: 0.189729\n",
            "[134]\tvalid_0's binary_logloss: 0.187313\n",
            "[135]\tvalid_0's binary_logloss: 0.189279\n",
            "[136]\tvalid_0's binary_logloss: 0.191068\n",
            "[137]\tvalid_0's binary_logloss: 0.192414\n",
            "[138]\tvalid_0's binary_logloss: 0.191255\n",
            "[139]\tvalid_0's binary_logloss: 0.193453\n",
            "[140]\tvalid_0's binary_logloss: 0.196969\n",
            "[141]\tvalid_0's binary_logloss: 0.196378\n",
            "[142]\tvalid_0's binary_logloss: 0.196367\n",
            "[143]\tvalid_0's binary_logloss: 0.19869\n",
            "[144]\tvalid_0's binary_logloss: 0.200352\n",
            "[145]\tvalid_0's binary_logloss: 0.19712\n",
            "오차 행렬\n",
            "[[33  4]\n",
            " [ 1 76]]\n",
            "정확도: 0.9561, 정밀도: 0.9500, 재현율: 0.9870, F1: 0.9682, AUC: 0.9905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. soft voting Hard voting"
      ],
      "metadata": {
        "id": "b3qj8BS4Nc9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처: https://cori.tistory.com/170\n",
        "\n",
        "[개요] \n",
        "\n",
        "Hard Voting, Soft Voting이 무엇인지 알아보고, 이들을 활용하는 예제를 다뤄본다.\n",
        "\n",
        " \n",
        "\n",
        "[내용 정리]\n",
        "\n",
        "1. Voting \n",
        "\n",
        "0) 정의 \n",
        "\n",
        "-> 서로 다른 종류의 알고리즘들을 결합하여 다수결 방식으로 최종 결과 출력한다. \n",
        "\n",
        " \n",
        "\n",
        "1) Hard Voting \n",
        "\n",
        "-> 다수의 추정기가 예측한 값들 중 많은 것을 선택한다."
      ],
      "metadata": {
        "id": "z0HAEmS4NeS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Soft Voting\n",
        "\n",
        "· 서로 다른 종류의 알고리즘들을 결합하여 다수결 방식으로 최종 결과 출력\n",
        "\n",
        "· 다수의 추정기에서 각 레이블 별 예측한 확률들의 평균을 내서 높은 레이블값을 결과값으로 선택\n",
        "\n",
        "· Hard Voting보다 Soft Voting의 성능이 더 좋다. "
      ],
      "metadata": {
        "id": "t8o9Z7lrRBv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) voting 함수 \n",
        "\n",
        "sklearn.ensemble.VotingClassifier\n",
        "\n",
        " \n",
        "\n",
        "· estimators: 앙상블할 모델들을 설정한다. (\"추정기이름\", 추정기)의 튜플을 리스트로 묶어서 전달\n",
        "\n",
        "· voting: voting 방식을 설정한다. (hard: 기본값, soft: 지정) "
      ],
      "metadata": {
        "id": "TMdibixTRG2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 4-1. 시간별/제조사별 불량률 데이터로 생존분석하여 25, 30, 35개월 후 불량률 계산\n",
        "\n",
        "lifelines.KaplanMeierFitter\n",
        "\n",
        "# 4-2. 로그 순위법으로 제조사별 차이 검정\n",
        "\n",
        "lifelines.statistics.logrank_test\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "W47fsz61RJcU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HkghmdXMAlOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 5. 시식 전 후 구매 의도를 가진 사람 비율 차이 검정 # 교차표 형식으로 표 그림 제공\n",
        "\n",
        "scipy.stats.chi2_contingency\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "mKc922uRAlln"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nagpLW5IAoFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 6. 2개 열을 가진 성적 데이터로 각 열의 분산 차이 검정 # 각 열의 행 개수가 달랐음\n",
        "\n",
        "scipy.stats.levene ?\n",
        "\n",
        " \n",
        "\n",
        "7. 몸무게 통제 시 나이와 콜레스테롤 지수 편상관분석 # pingouin.partial_corr"
      ],
      "metadata": {
        "id": "qJ-LfoeuAoS3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5ny-tqgAruL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 7. 몸무게 통제 시 나이와 콜레스테롤 지수 편상관분석 \n",
        "\n",
        "pingouin.partial_corr"
      ],
      "metadata": {
        "id": "1BfAb1zbAr1V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZK92sQ2As8G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}